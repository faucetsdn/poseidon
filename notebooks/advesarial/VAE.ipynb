{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'floatX=float32,device=gpu'\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "#from matplotlib import pyplot as plt\n",
    "#import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import gzip\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "#from load import mnist\n",
    "\n",
    "#import Plots\n",
    "import pickle\n",
    "srng = RandomStreams()\n",
    "\n",
    "f = open(\"costs.txt\", 'w')\n",
    "f.write(\"Starting...\\n\")\n",
    "f.close()\n",
    "\n",
    "# writes cost to txt file\n",
    "def write(str):\n",
    "    f = open(\"costs.txt\", 'a')\n",
    "    f.write(str)\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def init_biases(n_out):\n",
    "    return theano.shared(floatX(np.zeros(n_out)))\n",
    "\n",
    "def plotter(samples, predictions, img_x, idx):\n",
    "    #plot_all_filters(Ws, idx)\n",
    "    shp = (samples.shape[0], 1, img_x, img_x)\n",
    "    samples = samples.reshape(shp)\n",
    "    predictions = predictions.reshape(shp)\n",
    "    plot_predictions_grid(samples, predictions, idx, shp, 'preds')\n",
    "    return\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "# Gaussian prior\n",
    "def model(X, w1, b1, wmu, bmu, wsigma, bsigma, w2, b2, w3, b3, e):\n",
    "    h1 = rectify(T.dot(X, w1) + b1) # encoding\n",
    "    mu = T.dot(h1, wmu) + bmu # using encoding to parameterize mu\n",
    "    log_sigma = 0.5 * (T.dot(h1, wsigma) + bsigma) # using enc to param sigma\n",
    "    z = mu + T.exp(log_sigma) * e \n",
    "    h2 = rectify(T.dot(z, w2) + b2) # decoder\n",
    "    out = rectify(T.dot(h2, w3) + b3) # decoder\n",
    "    return mu, log_sigma, z, out\n",
    "#need mu, log_sigma, z, wmu/bmu, wsigma/bsigma\n",
    "#X is input, but you can input unif random X\n",
    "\n",
    "def generate(Z, w2, b2, w3, b3):\n",
    "    h2 = rectify(T.dot(Z, w2) + b2)\n",
    "    out = rectify(T.dot(h2, w3) + b3)\n",
    "    return out\n",
    "\n",
    "    \n",
    "def get_params(code_size):\n",
    "    n_hidden1 = 600\n",
    "    n_code = code_size\n",
    "    n_hidden2 = 600\n",
    "    w1 = init_weights((784, n_hidden1))\n",
    "    b1 = init_biases(n_hidden1)\n",
    "    wmu = init_weights((n_hidden1, n_code))\n",
    "    bmu = init_biases(n_code)\n",
    "    wsigma = init_weights((n_hidden1, n_code))\n",
    "    bsigma = init_biases(n_code)\n",
    "    w2 = init_weights((n_code, n_hidden2))\n",
    "    b2 = init_biases(n_hidden2)\n",
    "    w3 = init_weights((n_hidden2, 784))\n",
    "    b3 = init_biases(784)\n",
    "    return w1, b1, wmu, bmu, wsigma, bsigma, w2, b2, w3, b3\n",
    "\n",
    "def one_hot(x,n):\n",
    "\tif type(x) == list:\n",
    "\t\tx = np.array(x)\n",
    "\tx = x.flatten()\n",
    "\to_h = np.zeros((len(x),n))\n",
    "\to_h[np.arange(len(x)),x] = 1\n",
    "\treturn o_h\n",
    "\n",
    "\n",
    "#def load_data(dataset):\n",
    "def mnist(ntrain=60000,ntest=10000,onehot=True):\n",
    "    ''' Loads the dataset\n",
    "    :type dataset: string\n",
    "    :param dataset: the path to the dataset (here MNIST)\n",
    "    '''\n",
    "    path = \"/data/fs4/datasets/mnist/mnist.pkl.gz\"\n",
    "    f = gzip.open(path, 'rb')\n",
    "    train_set, valid_set, test_set = pickle.load(f)\n",
    "    f.close()\n",
    "    # train_set, valid_set, test_set format: tuple(input, target)\n",
    "    # input is an numpy.ndarray of 2 dimensions (a matrix)\n",
    "    # which row's correspond to an example. target is a\n",
    "    # numpy.ndarray of 1 dimensions (vector)) that have the same length as\n",
    "    # the number of rows in the input. It should give the target\n",
    "    # target to the example with the same index in the input.\n",
    "    print(\"Done.\")\n",
    "    #return (train_set, valid_set, test_set)\n",
    "    if onehot:\n",
    "        trY = one_hot(train_set[1], 10)\n",
    "        teY = one_hot(valid_set[1], 10)\n",
    "    else:\n",
    "        trY = np.asarray(train_set[1])\n",
    "        teY = np.asarray(valid_set[1])\n",
    "    trX = train_set[0]\n",
    "    teX = valid_set[0]\n",
    "    print(trX.shape)\n",
    "    trX = trX.reshape(trX.shape[0], 1, 28, 28)\n",
    "    teX = teX.reshape(teX.shape[0], 1, 28, 28)\n",
    "    return trX, trY, teX, teY, 1, 28\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import scipy\n",
    "import theano\n",
    "def caltech(onehot=True, num_imgs_to_load=1000):\n",
    "    path = \"data-caltech/101_ObjectCategories/\"\n",
    "\n",
    "    # load file names\n",
    "    fnames = []\n",
    "    cats = {}\n",
    "    for path, subdirs, files in os.walk(path):\n",
    "        if len(files) > 0:\n",
    "            cats[path] = []\n",
    "            #print(path)\n",
    "        for name in files:\n",
    "            fnames.append(os.path.join(path, name))\n",
    "            cats[path].append(os.path.join(path, name))\n",
    "\n",
    "\n",
    "    # load images\n",
    "    i=0\n",
    "    for k in cats.keys():\n",
    "        cats[i] = cats[k]\n",
    "        del cats[k]\n",
    "        i += 1\n",
    "    #print(cats.keys())\n",
    "    \n",
    "    pics = []\n",
    "    imgshape = []\n",
    "    #rand = np.array(fnames)\n",
    "    count = 0\n",
    "    # for img in fnames:\n",
    "    #     if count >= num_imgs_to_load:\n",
    "    #         break\n",
    "    #     count += 1\n",
    "    #     pic = scipy.misc.imread(img)\n",
    "    #     if len(pic.shape)==3:\n",
    "    #         if pic.shape[0] >= 220 and pic.shape[1] >= 220:\n",
    "    #             pic = pic[20:20+200, 20:20+200, :]\n",
    "    #             pic = scipy.misc.imresize(pic, size=(60,60))\n",
    "    #             imgshape = pic.shape\n",
    "    #             pics.append(pic)\n",
    "    #             labels.append()\n",
    "    \n",
    "    labels = []\n",
    "    for label, vals in cats.items():\n",
    "        for val in vals:\n",
    "            if count >= num_imgs_to_load:\n",
    "                break\n",
    "            count += 1\n",
    "            pic = scipy.misc.imread(val)\n",
    "            if len(pic.shape)==3:\n",
    "                if pic.shape[0] >= 220 and pic.shape[1] >= 220:\n",
    "                    pic = pic[20:20+200, 20:20+200, :]\n",
    "                    pic = scipy.misc.imresize(pic, size=(60,60))\n",
    "                    imgshape = pic.shape\n",
    "                    pics.append(pic)\n",
    "                    labels.append(label)\n",
    "    \n",
    "        \n",
    "    X = np.array(pics)\n",
    "    Y = np.array(labels)\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    if onehot:\n",
    "        Y = one_hot(Y, i)\n",
    "    print(Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# data will be reshaped as (num_imgs, num_channels, height, width)\n",
    "# in this case:            (50000, 3, 32, 32)\n",
    "def cifar10(onehot=True):\n",
    "    path = \"data-cifar10\"\n",
    "    X = np.zeros((50000, 3072))\n",
    "    Y = np.zeros((50000, 1)).astype(int)\n",
    "    for i in range(1,6):\n",
    "        f = open(os.path.join(path, \"data_batch_\" + str(i)), 'rb')\n",
    "        dict = pickle.load(f, encoding=\"latin1\")\n",
    "        X[(i-1) * 10000: i * 10000,:] = dict['data']\n",
    "        Y[(i-1) * 10000: i * 10000,:] = np.array(dict['labels']).reshape((10000,1)).astype(int)\n",
    "    print(Y.dtype)\n",
    "    Y = one_hot(Y, 10)\n",
    "    print(Y.shape)\n",
    "    print(Y[:10, :])\n",
    "    X = X.reshape(50000, 3, 32, 32)\n",
    "\n",
    "    print(\"test\")\n",
    "    f = open(os.path.join(path, \"test_batch\"), 'rb')\n",
    "    dict = pickle.load(f, encoding=\"latin1\")\n",
    "    X_test = dict['data'].reshape(10000, 3, 32, 32)\n",
    "    Y_test = np.array(dict['labels']).reshape((10000,1)).astype(int)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "    Y_test = one_hot(Y_test, 10)\n",
    "    return X, Y, X_test, Y_test, 3, 32\n",
    "\n",
    "\n",
    "def load_data(dataset):\n",
    "    if dataset == \"mnist\":\n",
    "        return mnist()\n",
    "    if dataset == \"cifar10\":\n",
    "        return cifar10()\n",
    "    \n",
    "#---------------------------------------------------------------------\n",
    "def plot_filters(w, channels, idx, title):\n",
    "    if channels == 1:\n",
    "        plot_grey_filters(w, idx, title)\n",
    "    elif channels == 3:\n",
    "        plot_color_filters(w, idx, title)\n",
    "\n",
    "def plot_grey_filters(x, idx, title=\"\"):\n",
    "    num_filters = x.shape[0]\n",
    "    numrows = 10\n",
    "    numcols = int(np.ceil(num_filters/10))\n",
    "    plt.figure(figsize=(numrows, numcols))\n",
    "    gs = gridspec.GridSpec(numcols, numrows)\n",
    "    gs.update(wspace=0.1)\n",
    "    gs.update(hspace=0.0)\n",
    "    \n",
    "    print(\"Plotting filters...\")\n",
    "    print(x.shape)\n",
    "    for i in range(num_filters):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        w = x[i, :, :, :]\n",
    "        w = np.swapaxes(w, 0, 1)\n",
    "        w = np.swapaxes(w, 1, 2)\n",
    "        ax.imshow(w[:, :, 0], cmap=plt.cm.gist_yarg,\n",
    "                  interpolation='nearest', aspect='equal')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.axis('off')\n",
    "    plt.savefig(os.path.join('convfilters', title + '_' + str(idx) + '_convcaustics.png'))\n",
    "    plt.close('all')\n",
    "\n",
    "def plot_color_filters(x, idx, title=\"\"):\n",
    "    num_filters = x.shape[0]\n",
    "    numrows = 10\n",
    "    numcols = int(np.ceil(num_filters/10))\n",
    "    plt.figure(figsize=(numrows, numcols))\n",
    "    gs = gridspec.GridSpec(numcols, numrows)\n",
    "    gs.update(wspace=0.1)\n",
    "    gs.update(hspace=0.0)\n",
    "\n",
    "    print(\"plotting color filters\")\n",
    "    for i in range(num_filters):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        w = x[i, :, :, :]\n",
    "        w = np.swapaxes(w, 0, 1)\n",
    "        w = np.swapaxes(w, 1, 2)\n",
    "\n",
    "        #normalize\n",
    "        \n",
    "        r = w[:,:,0] - np.min(w[:,:,0])\n",
    "        g = w[:,:,1] - np.min(w[:,:,1])\n",
    "        b = w[:,:,2] - np.min(w[:,:,2])\n",
    "        r = r * 1.0 / np.max(r)\n",
    "        g = g * 1.0 / np.max(g)\n",
    "        b = b * 1.0 / np.max(b)\n",
    "        w = np.dstack((r,g,b))\n",
    "        ax.imshow(w,\n",
    "                  cmap=plt.cm.gist_yarg,\n",
    "                  interpolation='nearest',\n",
    "                  aspect='equal')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.axis('off')\n",
    "    plt.savefig(os.path.join('convfilters', title+ '_' + str(idx) + '_convcaustics.png'))\n",
    "    print(os.path.join('convfilters', title+ '_' + str(idx) + '_convcaustics.png'))\n",
    "    plt.close('all')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "def plot_predictions(samples, predictions, k, batch_size, imgshape):\n",
    "    samples = samples.reshape(batch_size, 3, imgshape, imgshape)\n",
    "    predictions = predictions.reshape(batch_size, 3, imgshape, imgshape)\n",
    "    samples = np.swapaxes(samples, 1,2)\n",
    "    samples = np.swapaxes(samples, 2,3)\n",
    "    predictions = np.swapaxes(predictions, 1,2)\n",
    "    predictions = np.swapaxes(predictions, 2,3)\n",
    "    for i in range(samples.shape[0]):\n",
    "        fig = plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(samples[i, :, :, :],\n",
    "                cmap=plt.cm.gist_yarg, interpolation='nearest',\n",
    "                aspect='equal')\n",
    "        path = \"convpredictions\"\n",
    "        fname = str(k) + '_' + str(i) + 'sample_IN.png'\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.savefig(os.path.join(path, fname), dpi=imgshape)\n",
    "        plt.close('all')\n",
    "        fig = plt.figure(figsize=(5, 5))\n",
    "        print(predictions[i, :, :, :].shape)\n",
    "        print(predictions[i, :, :, :])\n",
    "        plt.imshow(predictions[i, :, :, :],\n",
    "                cmap=plt.cm.gist_yarg, interpolation='nearest',\n",
    "                aspect='equal')\n",
    "        fname = str(k) + '_' + str(i) + 'sample_OUT.png'\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.savefig(os.path.join(path, fname), dpi=imgshape)\n",
    "        plt.close('all')\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "def plot_volume(volumes, k, title):\n",
    "    for ind in [0,4]:\n",
    "        vols = volumes[ind,:]\n",
    "        vols = (vols-np.min(vols))/(np.max(vols)-np.min(vols))\n",
    "        print(volumes.shape)\n",
    "        numrows = 10\n",
    "        numcols = int(np.ceil(vols.shape[0]/10))\n",
    "        plt.figure(figsize=(numrows, numcols))\n",
    "        gs = gridspec.GridSpec(numcols, numrows)\n",
    "        gs.update(wspace=0.1)\n",
    "        gs.update(hspace=0.0)\n",
    "        \n",
    "        for i in range(vols.shape[0]):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            if i < vols.shape[0]:\n",
    "                w = vols[i,:]\n",
    "                \n",
    "                ax.imshow(w,\n",
    "                        cmap=plt.cm.gist_yarg,\n",
    "                        interpolation='nearest',\n",
    "                        aspect='equal')\n",
    "                ax.set_xticklabels([])\n",
    "                ax.set_yticklabels([])\n",
    "                ax.axis('off')\n",
    "        if ind==0:\n",
    "            plt.savefig(os.path.join('convvolumes', title + '_' + str(k) + '_' + '_vol_A.png'))\n",
    "        else:\n",
    "            plt.savefig(os.path.join('convvolumes', title + '_' + str(k) + '_' + '_vol_B.png'))\n",
    "        plt.close('all')\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "def plot_predictions_grid(samples, predictions, k, imgshape, title=\"\"):\n",
    "    if imgshape[1] == 1:\n",
    "        predictions_grid_grey(samples, predictions, k, imgshape, title)\n",
    "    elif imgshape[1] == 3:\n",
    "        predictions_grid_color(samples, predictions, k, imgshape, title)\n",
    "    return\n",
    "\n",
    "def predictions_grid_color(samples, predictions, k, imgshape, title):\n",
    "    batch_size = samples.shape[0]\n",
    "    print(\"printintg predictions:\")\n",
    "    print(samples.shape)\n",
    "    print(imgshape)\n",
    "    print(predictions.shape)\n",
    "    samples = samples.reshape(batch_size, imgshape[1], imgshape[2], imgshape[3])\n",
    "    predictions = predictions.reshape(batch_size, imgshape[1], imgshape[2], imgshape[3])\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    gs = gridspec.GridSpec(5, 2)\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        if i % 2 == 0:\n",
    "            w = samples[i/2, :, :, :]\n",
    "        else:\n",
    "            w = predictions[i/2, :, :, :]\n",
    "        w = np.swapaxes(w, 0, 1)\n",
    "        w = np.swapaxes(w, 1, 2)\n",
    "        ax.imshow(w,\n",
    "                  cmap=plt.cm.gist_yarg,\n",
    "                  interpolation='nearest',\n",
    "                  aspect='equal')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.axis('off')\n",
    "    gs.update(wspace=0)\n",
    "    plt.savefig(os.path.join('convpredictions', str(k) + '_' + title + '.png'),\n",
    "                bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "'convpredictions/0_preds.png'\n",
    "def predictions_grid_grey(samples, predictions, idx, imgshape, title):\n",
    "    batch_size = samples.shape[0]\n",
    "    samples = samples.reshape(batch_size, imgshape[2], imgshape[3])\n",
    "    predictions = predictions.reshape(batch_size, imgshape[2], imgshape[3])\n",
    "    plt.figure(figsize=(6, 10))\n",
    "    gs = gridspec.GridSpec(6, 2)\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        if i % 2 == 0:\n",
    "            w = samples[i/2, :, :]\n",
    "        else:\n",
    "            w = predictions[i/2, :, :]\n",
    "            \n",
    "        ax.imshow(w,\n",
    "                  cmap=plt.cm.gist_yarg,\n",
    "                  interpolation='nearest',\n",
    "                  aspect='equal',\n",
    "                  vmin=0, vmax=1)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig('/data/fs4/home/bradh/vaeOutput/'+str(idx)+'convpredictions.png',\n",
    "                bbox_inches='tight')\n",
    "    #plt.savefig(os.path.join('convpredictions', str(idx) + '_' + title + '.png'),\n",
    "    #            bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "    \n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "def plot_costs(costs):\n",
    "    #print(costs)\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.log(costs))\n",
    "    plt.savefig('convcosts.png')\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def plot_testimg(imgs):\n",
    "    for i in range(np.min([imgs.shape[0], 10])):\n",
    "        img = imgs[i, :]\n",
    "        #img = img.reshape(ch28, 28)\n",
    "        img = np.swapaxes(img, 0, 1)\n",
    "        img = np.swapaxes(img, 1, 2)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        print(img.shape)\n",
    "        ax.imshow(img, cmap=plt.cm.gist_yarg)#, interpolation='nearest')\n",
    "    # cmap=plt.cm.gist_yarg,\n",
    "    # interpolation='nearest',\n",
    "    # aspect='equal')\n",
    "        plt.savefig(str(i) + '_testimg.png')\n",
    "        #plt.savefig(os.path.join('fanta', str(i) + '_testimg.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trX, trY, teX, teY, channels, img_x = mnist(onehot=True)\n",
    "trX = trX.reshape(trX.shape[0], 784)\n",
    "teX = teX.reshape(teX.shape[0], 784)\n",
    "X = T.fmatrix()\n",
    "e = T.matrix()\n",
    "\n",
    "n_code = 2\n",
    "\n",
    "w1, b1, wmu, bmu, wsigma, bsigma, w2, b2, w3, b3 = get_params(n_code)\n",
    "\n",
    "mu, log_sigma, z, out = model(X, w1, b1, wmu, bmu, wsigma, bsigma, w2, b2, w3, b3, e)\n",
    "recon_cost = T.sum(T.sqr(X-out))\n",
    "kl_cost = 0.5 * T.sum(1 + 2 * log_sigma - mu ** 2 - T.exp(2 * log_sigma))\n",
    "\n",
    "cost = recon_cost - kl_cost\n",
    "\n",
    "params = [w1, b1, wmu, bmu, wsigma, bsigma, w2, b2, w3, b3]\n",
    "updates = RMSprop(cost, params, lr=0.001)\n",
    "\n",
    "train = theano.function(inputs=[X, e], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "reconstruct = theano.function(inputs=[X, e], outputs=[out, cost], allow_input_downcast=True)\n",
    "\n",
    "zfan = T.fmatrix()\n",
    "fantasy = generate(zfan, w2, b2, w3, b3)\n",
    "fantasize = theano.function(inputs=[zfan], outputs=fantasy, allow_input_downcast=True)    \n",
    "\n",
    "for i in range(101):\n",
    "    for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "        c = train(trX[start:end], floatX(np.random.randn(128, n_code)))\n",
    "    \n",
    "    samples = teX[:10, :]        \n",
    "    r, cost = reconstruct(samples, floatX(np.random.randn(10, n_code)))\n",
    "    print(str(i)+'  ', cost)\n",
    "    write(str(i) + \": \" + str(cost))\n",
    "    plotter(samples, r, 28, i)\n",
    "    \n",
    "    samples = floatX(np.random.randn(20, n_code))\n",
    "    f = fantasize(samples)\n",
    "    f1 = f[:10, :]\n",
    "    f2 = f[10:, :]\n",
    "    shp = (f1.shape[0], 1, 28, 28)\n",
    "    f1 = f1.reshape(shp)\n",
    "    f2 = f2.reshape(shp)\n",
    "    plot_predictions_grid(f1, f2, i, shp, 'generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian prior\n",
    "def model(X, w1, b1, wmu, bmu, wsigma, bsigma, w2, b2, w3, b3, e):\n",
    "    h1 = rectify(T.dot(X, w1) + b1) # encoding\n",
    "    mu = T.dot(h1, wmu) + bmu # using encoding to parameterize mu\n",
    "    log_sigma = 0.5 * (T.dot(h1, wsigma) + bsigma) # using enc to param sigma\n",
    "    z = mu + T.exp(log_sigma) * e \n",
    "    h2 = rectify(T.dot(z, w2) + b2) # decoder\n",
    "    out = rectify(T.dot(h2, w3) + b3) # decoder\n",
    "    return mu, log_sigma, z, out\n",
    "# need mu, log_sigma, z, wmu/bmu, wsigma/bsigma\n",
    "# X is input, but you can input unif random X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
